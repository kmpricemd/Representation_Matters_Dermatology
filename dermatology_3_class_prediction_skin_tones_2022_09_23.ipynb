{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "from timeit import default_timer as timer\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, precision_recall_curve, matthews_corrcoef, auc, accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.utils import shuffle\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models\n",
    "import torch\n",
    "from torch import optim, cuda\n",
    "from torch.utils.data import DataLoader, sampler\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "from collections import OrderedDict\n",
    "from torchsummary import summary\n",
    "from torchvision.transforms import InterpolationMode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv('fitzpatrick17k.csv').drop(['Unnamed: 0'],axis=1)\n",
    "data_df = data_df[data_df.fitzpatrick!=-1].reset_index(drop=True)\n",
    "data_df = data_df.dropna(subset=['url']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = os.listdir('fitzpatrick17k_dataset_url_download/')\n",
    "file_list = [x[:-4] for x in file_list]\n",
    "data_df = data_df[data_df.md5hash.isin(file_list)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.insert(2,'path','x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.path =  '/tf/notebooks/SSD_data/dermatology_fitzpatrick17k_dataset/fitzpatrick17k_dataset_url_download/' + data_df.md5hash + '.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15964, 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    4796\n",
       "3    3296\n",
       "1    2941\n",
       "4    2776\n",
       "5    1527\n",
       "6     628\n",
       "Name: fitzpatrick, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.fitzpatrick.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_df.insert(2,\"actinic keratosis\",0)\n",
    "data_df.insert(2,\"basal cell carcinoma\",0)\n",
    "data_df.insert(2,\"melanoma\",0)\n",
    "data_df.insert(2,\"squamous cell carcinoma\",0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "bcc = ['basal cell carcinoma',\n",
    "       'basal cell carcinoma morpheiform',\n",
    "       'solid cystic basal cell carcinoma']\n",
    "data_df['basal cell carcinoma'].loc[data_df.label.isin(bcc)]=1\n",
    "melanoma = ['malignant melanoma',\n",
    "            'melanoma',\n",
    "            'superficial spreading melanoma ssm',\n",
    "            'lentigo maligna']\n",
    "data_df['melanoma'].loc[data_df.label.isin(melanoma)]=1\n",
    "data_df['squamous cell carcinoma'].loc[data_df.label==\"squamous cell carcinoma\"]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = shuffle(data_df, random_state=42).reset_index(drop=True)[12000:]\n",
    "data_df = shuffle(data_df, random_state=42).reset_index(drop=True)[:12000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "light_df = data_df[data_df.fitzpatrick.isin([1,2,3])]\n",
    "dark_df = data_df[data_df.fitzpatrick.isin([4,5,6])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_list = data_df.label.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 114/114 [00:00<00:00, 343.97it/s]\n"
     ]
    }
   ],
   "source": [
    "dark_combine_df = list(range(0,len(disease_list)))\n",
    "light_combine_df = list(range(0,len(disease_list)))\n",
    "\n",
    "for i in tqdm(range(0,len(disease_list))):\n",
    "    dark_combine_df[i] = shuffle(dark_df[dark_df.label==disease_list[i]], random_state=42)\n",
    "    light_combine_df[i] = shuffle(light_df[light_df.label==disease_list[i]], random_state=42)\n",
    "    dark_combine_df[i] = dark_combine_df[i][:len(light_combine_df[i])]\n",
    "    light_combine_df[i] = light_combine_df[i][:len(dark_combine_df[i])]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dark_append_df = dark_df[:0]\n",
    "light_append_df = light_df[:0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 114/114 [00:00<00:00, 313.24it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(0,len(dark_combine_df))):\n",
    "    dark_append_df = pd.concat([dark_append_df, dark_combine_df[i]])\n",
    "    light_append_df = pd.concat([light_append_df, light_combine_df[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = shuffle(pd.concat([dark_append_df, light_append_df]), random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6852, 12)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = data_df[:4941]\n",
    "validate_df = data_df[4941:5600]\n",
    "test_df = data_df[5600:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgtransResize = (512, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#TRANSFORM DATA\n",
    "\n",
    "normalize = transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
    "transformList = []\n",
    "transformList.append(transforms.Resize(imgtransResize,interpolation=InterpolationMode.BILINEAR))\n",
    "transformList.append(transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.05))\n",
    "transformList.append(transforms.RandomHorizontalFlip())\n",
    "transformList.append(transforms.RandomVerticalFlip())\n",
    "transformList.append(torchvision.transforms.RandomRotation(90, interpolation=InterpolationMode.BILINEAR))\n",
    "transformList.append(transforms.ToTensor())\n",
    "transformList.append(normalize)      \n",
    "transformSequence=transforms.Compose(transformList)\n",
    "\n",
    "\n",
    "val_transformList = []\n",
    "val_transformList.append(transforms.Resize(imgtransResize,interpolation=InterpolationMode.BILINEAR))\n",
    "val_transformList.append(transforms.ToTensor())\n",
    "val_transformList.append(normalize)   \n",
    "val_transformSequence=transforms.Compose(val_transformList)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_list = [\n",
    "'basal cell carcinoma',\n",
    "'melanoma',\n",
    "'squamous cell carcinoma'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = y_list\n",
    "class_names = y_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['basal cell carcinoma', 'melanoma', 'squamous cell carcinoma']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DermDataSet(Dataset):\n",
    "    def __init__(self, image_list_file, transform=None, policy=\"ones\"):\n",
    "        \"\"\"\n",
    "        image_list_file: path to the file containing images with corresponding labels.\n",
    "        transform: optional transform to be applied on a sample.\n",
    "        Upolicy: name the policy with regard to the uncertain labels\n",
    "        \"\"\"\n",
    "        image_names = []\n",
    "        labels = []\n",
    "\n",
    "        for row, line in image_list_file.iterrows():\n",
    "            #k+=1\n",
    "            image_name = line['path']\n",
    "            label = line[class_names]\n",
    "            \n",
    "            for i in range(len(label)):\n",
    "                label[i] = line[class_names[i]]\n",
    "            \n",
    "            image_names.append(image_name)\n",
    "            labels.append(label)\n",
    "\n",
    "        self.image_names = image_names\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Take the index of item and returns the image and its labels\"\"\"\n",
    " \n",
    "        image_name = self.image_names[index]\n",
    "        image = Image.open(image_name).convert(\"RGB\")\n",
    "        label = self.labels[index]\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, torch.FloatTensor(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "trBatchSize = 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next\n"
     ]
    }
   ],
   "source": [
    "#LOAD DATASET\n",
    "\n",
    "datasetTrain = DermDataSet(train_df, transformSequence, policy=\"ones\")\n",
    "datasetValid = DermDataSet(validate_df, val_transformSequence, policy=\"ones\")\n",
    "print(\"next\")\n",
    "\n",
    "#why can't I do shuffle true???\n",
    "dataLoaderTrain = DataLoader(dataset=datasetTrain, batch_size=trBatchSize, shuffle=True,  num_workers=32, pin_memory=True)\n",
    "dataLoaderVal = DataLoader(dataset=datasetValid, batch_size=trBatchSize, shuffle=False, num_workers=32, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DermTrainer():\n",
    "\n",
    "    def train (model, dataLoaderTrain, dataLoaderVal, nnClassCount, trMaxEpoch, launchTimestamp, checkpoint):\n",
    "        \n",
    "        overall_start = timer()\n",
    "        #SETTINGS: OPTIMIZER & SCHEDULER\n",
    "        optimizer = optim.Adam(model.parameters(), lr=3e-4, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=0, min_lr=1e-5, verbose=True)\n",
    "        epochs_no_improve = 0 \n",
    "        epoch_early_stop = 3\n",
    "        #SETTINGS: LOSS\n",
    "        loss = torch.nn.BCELoss()\n",
    "\n",
    "        #LOAD CHECKPOINT \n",
    "        if checkpoint != None and use_gpu:\n",
    "            modelCheckpoint = torch.load(checkpoint)\n",
    "            model.load_state_dict(modelCheckpoint['state_dict'])\n",
    "            optimizer.load_state_dict(modelCheckpoint['optimizer'])\n",
    "\n",
    "        \n",
    "        #TRAIN THE NETWORK\n",
    "        lossMIN = 100000\n",
    "        start = timer()\n",
    "        dir_path = dir_str+launchTimestamp\n",
    "        #os.mkdir(dir_path)\n",
    "        for epochID in range(0, trMaxEpoch):\n",
    "            \n",
    "            timestampTime = time.strftime(\"%H%M%S\")\n",
    "            timestampDate = time.strftime(\"%d%m%Y\")\n",
    "            timestampSTART = timestampDate + '-' + timestampTime\n",
    "            \n",
    "            batchs, losst = DermTrainer.epochTrain(model, dataLoaderTrain, optimizer, trMaxEpoch, epochID, nnClassCount, loss, start, lossMIN, launchTimestamp, dir_path)\n",
    "            print(\"\\n\")\n",
    "            outLoss, ground_truth, prediction, rocauc, aurocIndividual = DermTrainer.test(model, dataLoaderVal, nnClassCount, None, class_names, loss)\n",
    "            outLoss = outLoss.cpu().detach().numpy()\n",
    "            print(\"val loss: \" + str(outLoss))\n",
    "            print(\"\\n\")\n",
    "\n",
    "            timestampTime = time.strftime(\"%H%M%S\")\n",
    "            timestampDate = time.strftime(\"%d%m%Y\")\n",
    "            timestampEND = timestampDate + '-' + timestampTime\n",
    "            scheduler.step(outLoss)\n",
    "            \n",
    "            torch.save({'epoch': epochID + 1, 'state_dict': model.state_dict(), 'optimizer' : optimizer.state_dict()}, 'saved_models/dermatology_model_fitzpatrick_bin_' + str(epochID) + '_' + str(rocauc) + '.pth.tar')\n",
    "            #if lossVal < lossMIN:\n",
    "            #    best_epoch = epochID\n",
    "            #    lossMIN = lossVal    \n",
    "            #    torch.save({'epoch': epochID + 1, 'state_dict': model.state_dict(), 'best_loss': lossMIN, 'optimizer' : optimizer.state_dict()}, 'm-epoch_448x448_'+str(epochID)+'-' + launchTimestamp + '.pth.tar')\n",
    "                #print ('Epoch [' + str(epochID + 1) + '] [save] [' + timestampEND + '] loss= ' + str(lossVal))\n",
    "            #else:\n",
    "            #    print ('Epoch [' + str(epochID + 1) + '] [----] [' + timestampEND + '] loss= ' + str(lossVal))\n",
    "            \n",
    "   \n",
    "        return batchs, losst        \n",
    "    #-------------------------------------------------------------------------------- \n",
    "       \n",
    "    def epochTrain(model, dataLoader, optimizer, epochMax, epochID, classCount, loss, start, lossMIN, launchTimestamp, dir_path):\n",
    "        \n",
    "        batch = []\n",
    "        losstrain = []\n",
    "        losseval = []\n",
    "        \n",
    "        \n",
    "        \n",
    "        model.train()\n",
    "\n",
    "        for batchID, (varInput, target) in enumerate(dataLoaderTrain):\n",
    "            \n",
    "            varTarget = target.cuda(non_blocking = True)\n",
    "            \n",
    "            #varTarget = target.cuda()         \n",
    "\n",
    "\n",
    "            varOutput = model(varInput)\n",
    "            lossvalue = loss(varOutput, varTarget)\n",
    "                       \n",
    "            optimizer.zero_grad()\n",
    "            lossvalue.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            \n",
    "            l = lossvalue.item()\n",
    "            losstrain.append(l)\n",
    "            print(\n",
    "                f'Epoch: {epochID}\\t{100 * (batchID / (len(datasetTrain)//trBatchSize)):.1f}% complete. {timer() - start:.1f} seconds elapsed in epoch. Training loss: ' + str(round(np.mean(losstrain), 4)),\n",
    "                end='\\r')\n",
    "            \n",
    "            #if batchID==0:\n",
    "               # print(\"begin\")\n",
    "           \n",
    "        \n",
    "        return batch, losstrain\n",
    "    \n",
    "    #-------------------------------------------------------------------------------- \n",
    "    \n",
    "    def epochVal(model, dataLoader, optimizer, loss):\n",
    "        \n",
    "        model.eval()\n",
    "        \n",
    "        lossVal = 0\n",
    "        lossValNorm = 0\n",
    "        \n",
    "        outGT = torch.FloatTensor().cuda()\n",
    "        outPRED = torch.FloatTensor().cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, (varInput, target) in enumerate(dataLoader):\n",
    "                \n",
    "                target = target.cuda(non_blocking = True)\n",
    "                varOutput = model(varInput)\n",
    "                losstensor = loss(varOutput, target)\n",
    "                lossVal += losstensor\n",
    "                lossValNorm += 1\n",
    "                \n",
    "                outGT = torch.cat((outGT, target), 0).cuda()\n",
    "                outPRED = torch.cat((outPRED, varOutput), 0)\n",
    "        \n",
    "        outLoss = lossVal / lossValNorm\n",
    "\n",
    "        \n",
    "        outAUROC = []\n",
    "        \n",
    "        datanpGT = outGT.cpu().numpy()\n",
    "        datanpPRED = outPRED.cpu().numpy()\n",
    "        \n",
    "        for i in range(len(class_names)):\n",
    "            print(class_names[i])\n",
    "            #try:\n",
    "            outAUROC.append(roc_auc_score(datanpGT[:, i], datanpPRED[:, i]))\n",
    "            #except ValueError:\n",
    "            #    pass\n",
    "        \n",
    "        aurocMean = np.array(outAUROC).mean()\n",
    "        #print('validation_loss : ' + str(outLoss))\n",
    "        print ('\\nAUROC mean ', round(aurocMean, 5))\n",
    "        \n",
    "        for i in range (0, len(outAUROC)):\n",
    "            print (class_names[i], ' ', round(outAUROC[i],5))\n",
    "            print(\"\")\n",
    "        print(\"\\n\")\n",
    "        print(class_names)\n",
    "        return outLoss, datanpGT, datanpPRED, aurocMean\n",
    "    \n",
    "    \n",
    "    #--------------------------------------------------------------------------------     \n",
    "     \n",
    "    #---- Computes area under ROC curve \n",
    "    #---- dataGT - ground truth data\n",
    "    #---- dataPRED - predicted data\n",
    "    #---- classCount - number of classes\n",
    "    \n",
    "    def computeAUROC (dataGT, dataPRED, classCount):\n",
    "        \n",
    "        outAUROC = []\n",
    "        \n",
    "        datanpGT = dataGT.cpu().numpy()\n",
    "        datanpPRED = dataPRED.cpu().numpy()\n",
    "        \n",
    "        for i in range(classCount):\n",
    "            #print(class_names[i])\n",
    "            #try:\n",
    "            outAUROC.append(roc_auc_score(datanpGT[:, i], datanpPRED[:, i]))\n",
    "            #except ValueError:\n",
    "            #    pass\n",
    "        return outAUROC\n",
    "        \n",
    "        \n",
    "    #-------------------------------------------------------------------------------- \n",
    "    \n",
    "    \n",
    "    def test(model, dataLoaderTest, nnClassCount, checkpoint, class_names, loss):   \n",
    "        \n",
    "        #cudnn.benchmark = True\n",
    "        \n",
    "        if checkpoint != None and use_gpu:\n",
    "            modelCheckpoint = torch.load(checkpoint)\n",
    "            model.load_state_dict(modelCheckpoint['state_dict'])\n",
    "\n",
    "        #if use_gpu:\n",
    "        outGT = torch.FloatTensor().cuda()\n",
    "        outPRED = torch.FloatTensor().cuda()\n",
    "        #else:\n",
    "         #   outGT = torch.FloatTensor()\n",
    "          #  outPRED = torch.FloatTensor()\n",
    "        lossVal = 0\n",
    "        lossValNorm = 0\n",
    "        \n",
    "        model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i, (varInput, target) in enumerate(dataLoaderTest):\n",
    "                \n",
    "                target = target.cuda(non_blocking = True)\n",
    "                varOutput = model(varInput)\n",
    "                losstensor = loss(varOutput, target)\n",
    "                lossVal += losstensor\n",
    "                lossValNorm += 1\n",
    "                \n",
    "                outGT = torch.cat((outGT, target), 0).cuda()\n",
    "                outPRED = torch.cat((outPRED, varOutput), 0)\n",
    "        \n",
    "        outLoss = lossVal / lossValNorm\n",
    "        \n",
    "\n",
    "        aurocIndividual = DermTrainer.computeAUROC(outGT, outPRED, nnClassCount)\n",
    "        aurocMean = np.array(aurocIndividual).mean()\n",
    "        \n",
    "        print ('AUROC mean ', round(aurocMean, 5))\n",
    "        \n",
    "        for i in range (0, len(aurocIndividual)):\n",
    "            print (class_names[i], ' ', round(aurocIndividual[i],5))\n",
    "       \n",
    "        return outLoss, outGT, outPRED, aurocMean, aurocIndividual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnClassCount = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18(nn.Module):\n",
    "\n",
    "    def __init__(self, out_size):\n",
    "        super(ResNet18, self).__init__()\n",
    "        self.resnet18 = models.resnet18(pretrained=True)\n",
    "        num_ftrs = self.resnet18.fc.in_features\n",
    "        self.resnet18.fc = nn.Sequential(\n",
    "            nn.Linear(num_ftrs, out_size),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "            \n",
    "        print(out_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet18(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = ResNet18(nnClassCount).cuda()\n",
    "model = torch.nn.DataParallel(model).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "trMaxEpoch = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "timestampTime = time.strftime(\"%H%M%S\")\n",
    "timestampDate = time.strftime(\"%d%m%Y\")\n",
    "timestampLaunch = timestampDate + '-' + timestampTime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_str = 'dermatology_2022_09_23_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04102022-222849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\t100.0% complete. 35.7 seconds elapsed in epoch. Training loss: 0.159\n",
      "\n",
      "AUROC mean  0.85611\n",
      "basal cell carcinoma   0.8511\n",
      "melanoma   0.88133\n",
      "squamous cell carcinoma   0.83592\n",
      "val loss: 0.11917649\n",
      "\n",
      "\n",
      "Epoch: 1\t100.0% complete. 66.7 seconds elapsed in epoch. Training loss: 0.0907\n",
      "\n",
      "AUROC mean  0.87464\n",
      "basal cell carcinoma   0.90313\n",
      "melanoma   0.86864\n",
      "squamous cell carcinoma   0.85216\n",
      "val loss: 0.11422281\n",
      "\n",
      "\n",
      "Epoch: 2\t100.0% complete. 98.6 seconds elapsed in epoch. Training loss: 0.0848\n",
      "\n",
      "AUROC mean  0.87347\n",
      "basal cell carcinoma   0.91917\n",
      "melanoma   0.81766\n",
      "squamous cell carcinoma   0.88357\n",
      "val loss: 0.11103947\n",
      "\n",
      "\n",
      "Epoch: 3\t0.0% complete. 117.8 seconds elapsed in epoch. Training loss: 0.0851\r"
     ]
    }
   ],
   "source": [
    "print(timestampLaunch)\n",
    "batch, losst = DermTrainer.train(model, dataLoaderTrain, dataLoaderVal, nnClassCount, trMaxEpoch, timestampLaunch, checkpoint = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
